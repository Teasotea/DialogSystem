{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConversationalAI.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Teasotea/DialogSystem/blob/main/ConversationalAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xkvwa-_QmLt",
        "outputId": "f2dcbcf9-6e5e-4a13-cbe8-8d643a8a621d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8AfIs3-V_BY",
        "outputId": "ef9c1a83-1c2d-44c6-890e-75603c75c421"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "QEwDK7HzQGzZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "import nltk\n",
        "from sklearn.svm import OneClassSVM\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part I: Classification"
      ],
      "metadata": {
        "id": "dpkTWUHtQM8x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Greeting Classification"
      ],
      "metadata": {
        "id": "PncwCmo8bMzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data_greet, training_data_bye = [], []\n",
        "greetings =list(dict.fromkeys(['hi', \"hola\", 'hey', 'hello','morning', 'evening', 'good day', 'good morning', 'greetings', 'howdy', 'welcome', 'bonjour',\n",
        "             'buenas noches', 'buenos dias', 'salutation', 'salut', 'hail', 'salaam', 'aloha', 'good wishes',\n",
        "             'aloha', 'yoo-hoo', 'yawp', 'It’s always a pleasure to see you.', 'oh', 'ave', 'yo', 'hi there', \n",
        "             \"hi\", \"hello\", \"hey\", \"helloo\", \"hellooo\", \"g morining\", \"gmorning\", \"good morning\", \"morning\", \"good day\", \"good afternoon\", \"good evening\", \"greetings\", \"greeting\", \n",
        "             \"good to see you\", \"its good seeing you\", \"g’day\", \"howdy\"]))\n",
        "goodbyes = list(dict.fromkeys(['bye', 'exit', 'quit', 'See you later', 'I must be going', 'I’m off', \n",
        "                               'goodbye', 'Goodnight','I gotta take off', 'I’ve got to get going', \n",
        "                               'See ya!', 'Catch ya later', 'Ciao', 'Adios' ]))\n",
        "\n",
        "for i in greetings:\n",
        "  training_data_greet.append({\"class\":\"greeting\", \"sentence\":i})\n",
        "for i in goodbyes:\n",
        "  training_data_bye.append({'class':'goodbyes', 'sentence': i})\n",
        "  \n",
        "greet_df = pd.DataFrame(training_data_greet)\n",
        "bye_df = pd.DataFrame(training_data_bye)\n",
        "\n",
        "bye_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "09ZwJ8-8QDKG",
        "outputId": "70f4831e-14ec-4a86-c57d-28dc8f4e9459"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       class               sentence\n",
              "0   goodbyes                    bye\n",
              "1   goodbyes                   exit\n",
              "2   goodbyes                   quit\n",
              "3   goodbyes          See you later\n",
              "4   goodbyes        I must be going\n",
              "5   goodbyes                I’m off\n",
              "6   goodbyes                goodbye\n",
              "7   goodbyes              Goodnight\n",
              "8   goodbyes       I gotta take off\n",
              "9   goodbyes  I’ve got to get going\n",
              "10  goodbyes                See ya!\n",
              "11  goodbyes         Catch ya later\n",
              "12  goodbyes                   Ciao\n",
              "13  goodbyes                  Adios"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6225a290-d839-4361-8de0-bbe398fa6720\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>goodbyes</td>\n",
              "      <td>bye</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>goodbyes</td>\n",
              "      <td>exit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>goodbyes</td>\n",
              "      <td>quit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>goodbyes</td>\n",
              "      <td>See you later</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>goodbyes</td>\n",
              "      <td>I must be going</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>goodbyes</td>\n",
              "      <td>I’m off</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>goodbyes</td>\n",
              "      <td>goodbye</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>goodbyes</td>\n",
              "      <td>Goodnight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>goodbyes</td>\n",
              "      <td>I gotta take off</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>goodbyes</td>\n",
              "      <td>I’ve got to get going</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>goodbyes</td>\n",
              "      <td>See ya!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>goodbyes</td>\n",
              "      <td>Catch ya later</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>goodbyes</td>\n",
              "      <td>Ciao</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>goodbyes</td>\n",
              "      <td>Adios</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6225a290-d839-4361-8de0-bbe398fa6720')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6225a290-d839-4361-8de0-bbe398fa6720 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6225a290-d839-4361-8de0-bbe398fa6720');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "greetings_test = ['hi, there!','psst, can you tell me, which algorithm would work best if I have imbalanced dataset?','What\\'s your favourite music?','Hello? Somebody is here?', 'people often say welcome to guests','How many answers can you provide on this topic?',\"hola, hola!\", 'tell me about yourself','are you a bot','which movie would ypu suggest to watch this evening?', 'which laptop is the best for Data Science?', 'What about language generation task?','hey, bot:)', 'water']\n",
        "testy_greet = np.array([ 1, -1, -1, 1, -1, -1, 1, -1,  -1, -1, -1,  -1,  1, -1])\n",
        "\n",
        "bye_test = ['bye, bot:)', 'OK, then see you tomorrow', 'what does \\'exit\\' mean?', 'I\\'ll take off my hat behind you, bot', 'Let\\'s quit this conversation', 'How to translate \\'adios\\'?', 'Catch me, if you can!', 'Too boring( OK, see tou late then']\n",
        "testy_bye = np.array([ 1, 1, -1, -1, 1, -1, -1, 1])"
      ],
      "metadata": {
        "id": "nX3-pL5D-0VG"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One-Class Classification with SVM"
      ],
      "metadata": {
        "id": "HRQQKHtr5Pbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfD4NDIZR3b4",
        "outputId": "2fa9ba80-fba8-45d1-b24b-8d53d3af6087"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "vb0_TOEH5Vw7"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_words = 1000\n",
        "oov_token = '<UNK>'\n",
        "pad_type = 'post'\n",
        "trunc_type = 'post'"
      ],
      "metadata": {
        "id": "H35LmGn556Ya"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_greet = Tokenizer(num_words=num_words, oov_token=oov_token)\n",
        "tokenizer_greet.fit_on_texts(greetings)\n",
        "word_index_greet = tokenizer_greet.word_index\n",
        "train_sequences_greet = tokenizer_greet.texts_to_sequences(greetings)\n",
        "\n",
        "# Get max training sequence length\n",
        "maxlen_greet = max([len(x) for x in train_sequences_greet])\n",
        "\n",
        "# Pad the training sequences\n",
        "train_padded_greet = pad_sequences(train_sequences_greet, padding=pad_type, truncating=trunc_type, maxlen=maxlen_greet)\n",
        "\n",
        "# Output the results of our work\n",
        "print(\"Word index:\\n\", word_index_greet)\n",
        "print(\"\\nTraining sequences:\\n\", train_sequences_greet)\n",
        "# print(\"\\nPadded training sequences:\\n\", train_padded)\n",
        "print(\"\\nPadded training shape:\", train_padded_greet.shape)\n",
        "print(\"Training sequences data type:\", type(train_sequences_greet))\n",
        "print(\"Padded Training sequences data type:\", type(train_padded_greet))\n",
        "\n",
        "test_sequences_greet = tokenizer_greet.texts_to_sequences(greetings_test)\n",
        "test_padded_greet = pad_sequences(test_sequences_greet, padding=pad_type, truncating=trunc_type, maxlen=maxlen_greet)\n",
        "\n",
        "print(\"Testing sequences:\\n\", test_sequences_greet)\n",
        "print(\"\\nPadded testing sequences:\\n\", test_padded_greet)\n",
        "print(\"\\nPadded testing shape:\",test_padded_greet.shape)\n",
        "\n",
        "for x, y in zip(greetings_test, test_padded_greet):\n",
        "  print('{} -> {}'.format(x, y))"
      ],
      "metadata": {
        "id": "2e7CLftR59kQ",
        "outputId": "2e6044ab-9f1f-40ff-8ba8-2ff53702429a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word index:\n",
            " {'<UNK>': 1, 'good': 2, 'you': 3, 'hi': 4, 'morning': 5, 'evening': 6, 'to': 7, 'see': 8, 'hola': 9, 'hey': 10, 'hello': 11, 'day': 12, 'greetings': 13, 'howdy': 14, 'welcome': 15, 'bonjour': 16, 'buenas': 17, 'noches': 18, 'buenos': 19, 'dias': 20, 'salutation': 21, 'salut': 22, 'hail': 23, 'salaam': 24, 'aloha': 25, 'wishes': 26, 'yoo': 27, 'hoo': 28, 'yawp': 29, 'it’s': 30, 'always': 31, 'a': 32, 'pleasure': 33, 'oh': 34, 'ave': 35, 'yo': 36, 'there': 37, 'helloo': 38, 'hellooo': 39, 'g': 40, 'morining': 41, 'gmorning': 42, 'afternoon': 43, 'greeting': 44, 'its': 45, 'seeing': 46, 'g’day': 47}\n",
            "\n",
            "Training sequences:\n",
            " [[4], [9], [10], [11], [5], [6], [2, 12], [2, 5], [13], [14], [15], [16], [17, 18], [19, 20], [21], [22], [23], [24], [25], [2, 26], [27, 28], [29], [30, 31, 32, 33, 7, 8, 3], [34], [35], [36], [4, 37], [38], [39], [40, 41], [42], [2, 43], [2, 6], [44], [2, 7, 8, 3], [45, 2, 46, 3], [47]]\n",
            "\n",
            "Padded training shape: (37, 7)\n",
            "Training sequences data type: <class 'list'>\n",
            "Padded Training sequences data type: <class 'numpy.ndarray'>\n",
            "Testing sequences:\n",
            " [[4, 37], [1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [11, 1, 1, 1], [1, 1, 1, 15, 7, 1], [1, 1, 1, 1, 3, 1, 1, 1, 1], [9, 9], [1, 1, 1, 1], [1, 3, 32, 1], [1, 1, 1, 1, 1, 7, 1, 1, 6], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [10, 1], [1]]\n",
            "\n",
            "Padded testing sequences:\n",
            " [[ 4 37  0  0  0  0  0]\n",
            " [ 1  1  3  1  1  1  1]\n",
            " [ 1  1  1  1  0  0  0]\n",
            " [11  1  1  1  0  0  0]\n",
            " [ 1  1  1 15  7  1  0]\n",
            " [ 1  1  1  1  3  1  1]\n",
            " [ 9  9  0  0  0  0  0]\n",
            " [ 1  1  1  1  0  0  0]\n",
            " [ 1  3 32  1  0  0  0]\n",
            " [ 1  1  1  1  1  7  1]\n",
            " [ 1  1  1  1  1  1  1]\n",
            " [ 1  1  1  1  1  0  0]\n",
            " [10  1  0  0  0  0  0]\n",
            " [ 1  0  0  0  0  0  0]]\n",
            "\n",
            "Padded testing shape: (14, 7)\n",
            "hi, there! -> [ 4 37  0  0  0  0  0]\n",
            "psst, can you tell me, which algorithm would work best if I have imbalanced dataset? -> [1 1 3 1 1 1 1]\n",
            "What's your favourite music? -> [1 1 1 1 0 0 0]\n",
            "Hello? Somebody is here? -> [11  1  1  1  0  0  0]\n",
            "people often say welcome to guests -> [ 1  1  1 15  7  1  0]\n",
            "How many answers can you provide on this topic? -> [1 1 1 1 3 1 1]\n",
            "hola, hola! -> [9 9 0 0 0 0 0]\n",
            "tell me about yourself -> [1 1 1 1 0 0 0]\n",
            "are you a bot -> [ 1  3 32  1  0  0  0]\n",
            "which movie would ypu suggest to watch this evening? -> [1 1 1 1 1 7 1]\n",
            "which laptop is the best for Data Science? -> [1 1 1 1 1 1 1]\n",
            "What about language generation task? -> [1 1 1 1 1 0 0]\n",
            "hey, bot:) -> [10  1  0  0  0  0  0]\n",
            "water -> [1 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer_bye= Tokenizer(num_words=num_words, oov_token=oov_token)\n",
        "# tokenizer_bye.fit_on_texts(goodbyes)\n",
        "# word_index = tokenizer_bye.word_index\n",
        "# train_sequences_bye = tokenizer_bye.texts_to_sequences(goodbyes)\n",
        "\n",
        "# # Get max training sequence length\n",
        "# maxlen_bye = max([len(x) for x in train_sequences_bye])\n",
        "\n",
        "# # Pad the training sequences\n",
        "# train_padded_bye = pad_sequences(train_sequences_bye, padding=pad_type, truncating=trunc_type, maxlen=maxlen_bye)\n",
        "\n",
        "# # Output the results of our work\n",
        "# print(\"Word index:\\n\", word_index)\n",
        "# print(\"\\nTraining sequences:\\n\", train_sequences_bye)\n",
        "# # print(\"\\nPadded training sequences:\\n\", train_padded)\n",
        "# print(\"\\nPadded training shape:\", train_padded_bye.shape)\n",
        "# print(\"Training sequences data type:\", type(train_sequences_bye))\n",
        "# print(\"Padded Training sequences data type:\", type(train_padded_bye))\n",
        "\n",
        "# test_sequences_bye = tokenizer_greet.texts_to_sequences(bye_test)\n",
        "# test_padded_bye = pad_sequences(test_sequences_bye, padding=pad_type, truncating=trunc_type, maxlen=maxlen_bye)\n",
        "\n",
        "# print(\"Testing sequences:\\n\", test_sequences_bye)\n",
        "# print(\"\\nPadded testing sequences:\\n\", test_padded_bye)\n",
        "# print(\"\\nPadded testing shape:\",test_padded_bye.shape)\n",
        "\n",
        "# for x, y in zip(bye_test, test_padded_bye):\n",
        "#   print('{} -> {}'.format(x, y))"
      ],
      "metadata": {
        "id": "qmvd1PRBrV18",
        "outputId": "8faef3b3-2500-4219-dc44-70e2f37175a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word index:\n",
            " {'<UNK>': 1, 'see': 2, 'later': 3, 'i': 4, 'going': 5, 'off': 6, 'ya': 7, 'bye': 8, 'exit': 9, 'quit': 10, 'you': 11, 'must': 12, 'be': 13, 'i’m': 14, 'goodbye': 15, 'goodnight': 16, 'gotta': 17, 'take': 18, 'i’ve': 19, 'got': 20, 'to': 21, 'get': 22, 'catch': 23, 'ciao': 24, 'adios': 25}\n",
            "\n",
            "Training sequences:\n",
            " [[8], [9], [10], [2, 11, 3], [4, 12, 13, 5], [14, 6], [15], [16], [4, 17, 18, 6], [19, 20, 21, 22, 5], [2, 7], [23, 7, 3], [24], [25]]\n",
            "\n",
            "Padded training shape: (14, 5)\n",
            "Training sequences data type: <class 'list'>\n",
            "Padded Training sequences data type: <class 'numpy.ndarray'>\n",
            "Testing sequences:\n",
            " [[1, 1], [1, 1, 8, 3, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 3, 1], [1, 1, 1, 1], [1, 7, 1, 1], [1, 1, 1, 3, 1], [1, 1, 1, 8, 1, 1, 1]]\n",
            "\n",
            "Padded testing sequences:\n",
            " [[1 1 0 0 0]\n",
            " [1 1 8 3 1]\n",
            " [1 1 1 1 0]\n",
            " [1 1 1 1 1]\n",
            " [1 1 1 1 0]\n",
            " [1 7 1 1 0]\n",
            " [1 1 1 3 1]\n",
            " [1 1 1 8 1]]\n",
            "\n",
            "Padded testing shape: (8, 5)\n",
            "bye, bot:) -> [1 1 0 0 0]\n",
            "OK, then see you tomorrow -> [1 1 8 3 1]\n",
            "what does 'exit' mean? -> [1 1 1 1 0]\n",
            "I'll take off my hat behind you, bot -> [1 1 1 1 1]\n",
            "Let's quit this conversation -> [1 1 1 1 0]\n",
            "How to translate 'adios'? -> [1 7 1 1 0]\n",
            "Catch me, if you can! -> [1 1 1 3 1]\n",
            "Too boring( OK, see tou late then -> [1 1 1 8 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Greetings"
      ],
      "metadata": {
        "id": "7DdfkklKvFgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = OneClassSVM(gamma='scale', nu=0.01)\n",
        "model.fit(train_padded_greet)"
      ],
      "metadata": {
        "id": "eb7UqXT37vEF",
        "outputId": "750383b7-7722-45f5-fc86-b4cc966262de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneClassSVM(nu=0.01)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#+1 for normal examples, so-called inliers, and a -1 for outliers.\n",
        "yhat_greet = model.predict(test_padded_greet)"
      ],
      "metadata": {
        "id": "5gsn6d3c-UoE"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat_greet"
      ],
      "metadata": {
        "id": "ww8-v2DHB1FZ",
        "outputId": "c10a939b-cfc0-453d-ecb9-0fdf60749c3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1, -1, -1,  1, -1, -1,  1, -1, -1, -1, -1, -1,  1, -1])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = f1_score(testy_greet, yhat_greet, pos_label=-1)\n",
        "print('F1 Score: %.3f' % score)"
      ],
      "metadata": {
        "id": "eTyrubiFCmnr",
        "outputId": "83059200-7dea-431b-d4de-ee8fa8d2be76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_greet(sent):\n",
        "  l = [sent]\n",
        "  test_sequences = tokenizer_greet.texts_to_sequences(l)\n",
        "  test_padded= pad_sequences(test_sequences, padding=pad_type, truncating=trunc_type, maxlen=maxlen_greet)\n",
        "  pred_class_greet = model.predict(test_padded)\n",
        "  cl = int(*pred_class_greet)\n",
        "  return  cl\n",
        "  \n",
        "print(classify_greet('Hey! Lets talk, bot'))"
      ],
      "metadata": {
        "id": "6QRupywXHAqw",
        "outputId": "056ea521-6752-4aa7-b592-6d09d2b688fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### gooodbyes"
      ],
      "metadata": {
        "id": "Xjj0qaWhvKZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "a5MKUNGavaAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part II: Question Answering"
      ],
      "metadata": {
        "id": "bqc-tw4XQL2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "RVOiMcK5O1p6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "import requests\n",
        "\n",
        "# [ds for ds in datasets.list_datasets() if 'ml' in ds.lower()]"
      ],
      "metadata": {
        "id": "t9b584AubuXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_ds = datasets.load_dataset('squad', streaming = False)\n",
        "qa_ds"
      ],
      "metadata": {
        "id": "lOUBTz1KQOkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_ds['train'].description"
      ],
      "metadata": {
        "id": "fS-kZpaASXwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(qa_ds['train'].dataset_size)\n",
        "qa_ds['train'].features"
      ],
      "metadata": {
        "id": "joklgTTXQono"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_ds['train'].to_pandas().head()"
      ],
      "metadata": {
        "id": "zGit477NSxF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Science Interview Dataset"
      ],
      "metadata": {
        "id": "9Q8MZVVZSnyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa_data = pd.read_csv('https://raw.githubusercontent.com/Kizuna-Cheng/Data_Science_Interviews_NLP/main/data.csv')\n",
        "qa_data.head(7)"
      ],
      "metadata": {
        "id": "iKS3WdgOStnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_data.Questions[:10].tolist()"
      ],
      "metadata": {
        "id": "g4PbY6JQTJMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = [\n",
        "             'What does linear regression stands for?',\n",
        " 'What is the differencebetween collinearity and multicollinearity?',\n",
        " 'What are the cons of using a linear model?\\n',\n",
        " 'What are ridge and lasso regression?',\n",
        " 'How does K-Nearest neighbor work?',\n",
        " 'How to select k for k means?',\n",
        " 'Why is Naive Bayes “naive”?',\n",
        " 'When should I use SVM?',\n",
        "'What is pruning in decision trees?',\n",
        " 'What are random forests? Why is Naive Bayes better?']"
      ],
      "metadata": {
        "id": "V-ttfUuWTWQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## QA Baseline"
      ],
      "metadata": {
        "id": "6wutEbasSeDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getResults(questions, fn):\n",
        "    def getResult(q):\n",
        "        answer, score, prediction = fn(q)\n",
        "        return [q, prediction, answer, score]\n",
        "    return pd.DataFrame(list(map(getResult, questions)), columns=[\"Q\", \"Prediction\", \"A\", \"Score\"])"
      ],
      "metadata": {
        "id": "fbrYjBrDTesl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getNaiveAnswer(q):\n",
        "    row = qa_data.loc[qa_data['Questions'].str.contains(re.sub(r\"[^\\w'\\s)]+\", \"\", q),case=False)]\n",
        "    if len(row) > 0:\n",
        "        return row[\"Answers\"].values[0], 1, row[\"Questions\"].values[0]\n",
        "    else: return \"Sorry, I didn't get you\", 0, \"\"\n",
        "print(getNaiveAnswer('How does K-Nearest Neighbor work?'))\n",
        "getResults(test_data, getNaiveAnswer)"
      ],
      "metadata": {
        "id": "SPAO6GZdSbFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part III: Natural Language Generation"
      ],
      "metadata": {
        "id": "L3cyjAcBQDdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checkpoint \n",
        "checkpoint = \"microsoft/DialoGPT-medium\"\n",
        "# download and cache tokenizer\n",
        "tokenizer2 = AutoTokenizer.from_pretrained(checkpoint)\n",
        "# download and cache pre-trained model\n",
        "modelNLG = AutoModelForCausalLM.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "pCDZhsH2QhMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part IV: Bot Development"
      ],
      "metadata": {
        "id": "cp9LKdPgP-Io"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#change the code later, make it better\n",
        "class ChatBot():\n",
        "    def __init__(self):\n",
        "        # once chat starts, the history will be stored for chat continuity\n",
        "        self.chat_history_ids = None\n",
        "        # make input ids global to use them anywhere within the object\n",
        "        self.bot_input_ids = None\n",
        "        # a flag to check whether to end the conversation\n",
        "        self.end_chat = False\n",
        "        # greet while starting\n",
        "        self.welcome()\n",
        "        self.is_greeting = False\n",
        "        self.text_input = None\n",
        "        \n",
        "    def welcome(self):\n",
        "        print(\"Initializing ChatBot ...\")\n",
        "        # some time to get user ready\n",
        "        time.sleep(2)\n",
        "        print('Type \"bye\" or \"quit\" or \"exit\" to end chat \\n')\n",
        "        # give time to read what has been printed\n",
        "        time.sleep(3)\n",
        "\n",
        "        \n",
        "    def user_input(self):\n",
        "        # receive input from user\n",
        "        text = str(input(\"User    >> \"))\n",
        "        # end conversation if user wishes so\n",
        "        if text.lower().strip() in ['bye', 'quit', 'exit']:\n",
        "            # turn flag on \n",
        "            self.end_chat=True\n",
        "            # a closing comment\n",
        "            print('ChatBot >>  See you soon! Bye!')\n",
        "            time.sleep(1)\n",
        "            print('\\nQuitting ChatBot ...')\n",
        "        else:\n",
        "            # continue chat, preprocess input text\n",
        "            # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
        "            if classify_greet(text) == -1:\n",
        "              self.text_input = text\n",
        "            else: \n",
        "              self.is_greeting = True\n",
        "\n",
        "    def bot_greet(self):\n",
        "        greeting = np.random.choice([\n",
        "            \"Welcome, I am ChatBot, here for your kind service\",\n",
        "            \"Hey, Great day! I am your virtual assistant\",\n",
        "            \"Hello, it's my pleasure meeting you\",\n",
        "            \"Hi, I am a ChatBot. Let's chat!\"\n",
        "        ])\n",
        "        print(\"ChatBot >>  \" + greeting)\n",
        "        self.is_greeting = False\n",
        "\n",
        "    def bot_response(self):\n",
        "        self.new_user_input_ids = tokenizer2.encode(self.text_input + tokenizer2.eos_token, \\\n",
        "                                                       return_tensors='pt')\n",
        "        # append the new user input tokens to the chat history\n",
        "        # if chat has already begun\n",
        "        if self.chat_history_ids is not None:\n",
        "            self.bot_input_ids = torch.cat([self.chat_history_ids, self.new_user_input_ids], dim=-1) \n",
        "        else:\n",
        "            # if first entry, initialize bot_input_ids\n",
        "            self.bot_input_ids = self.new_user_input_ids\n",
        "        \n",
        "        # define the new chat_history_ids based on the preceding chats\n",
        "        # generated a response while limiting the total chat history to 1000 tokens, \n",
        "        self.chat_history_ids = modelNLG.generate(self.bot_input_ids, max_length=1000, \\\n",
        "                                               pad_token_id=tokenizer2.eos_token_id)\n",
        "            \n",
        "        # last ouput tokens from bot\n",
        "        response = tokenizer2.decode(self.chat_history_ids[:, self.bot_input_ids.shape[-1]:][0], \\\n",
        "                               skip_special_tokens=True)\n",
        "        # in case, bot fails to answer\n",
        "        if response == \"\":\n",
        "            response = self.random_response()\n",
        "        # print bot response\n",
        "        print('ChatBot >>  '+ response)\n",
        "        \n",
        "    def random_response(self):\n",
        "        i = -1\n",
        "        response = tokenizer2.decode(self.chat_history_ids[:, self.bot_input_ids.shape[i]:][0], \\\n",
        "                               skip_special_tokens=True)\n",
        "        # iterate over history backwards to find the last token\n",
        "        while response == '':\n",
        "            i = i-1\n",
        "            response = tokenizer2.decode(self.chat_history_ids[:, self.bot_input_ids.shape[i]:][0], \\\n",
        "                               skip_special_tokens=True)\n",
        "        # if it is a question, answer suitably\n",
        "        if response.strip() == '?':\n",
        "            reply = np.random.choice([\"I don't know\", \n",
        "                                     \"I am not sure\"])\n",
        "        # not a question? answer suitably\n",
        "        else:\n",
        "            reply = np.random.choice([\"Great\", \n",
        "                                      \"Fine. What's up?\", \n",
        "                                      \"Okay\"\n",
        "                                     ])\n",
        "        return reply"
      ],
      "metadata": {
        "id": "NG4bFpPiQhVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build a ChatBot object\n",
        "bot = ChatBot()\n",
        "# start chatting\n",
        "while True:\n",
        "    # receive user input\n",
        "    bot.user_input()\n",
        "    # check whether to end chat\n",
        "    if bot.end_chat:\n",
        "        break\n",
        "    # output bot response\n",
        "    if bot.is_greeting == False:\n",
        "      bot.bot_response()  \n",
        "    else: bot.bot_greet()  "
      ],
      "metadata": {
        "id": "YjL1zeLuQhip"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}